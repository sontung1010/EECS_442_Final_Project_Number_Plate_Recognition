{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "broke-custody",
      "metadata": {
        "id": "broke-custody"
      },
      "source": [
        "# Combination of Contour and YOLOv3\n",
        "This notebook shows the optimization of result by combining both the techniques. Please refer to the seperate implementaion of Contour method and YOLOv3 before going through this notebook.\n",
        "\n",
        "As seen previously, contour method gives an overall accuracy of 60.24% whereas YOLOv3 gave 74.10%. Although YOLOv3 gives better result, we'll try to optimize the result even more."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acoustic-spectrum",
      "metadata": {
        "id": "acoustic-spectrum"
      },
      "source": [
        "## Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "convertible-bangkok",
      "metadata": {
        "id": "convertible-bangkok"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D\n",
        "from IPython.display import Image\n",
        "import argparse\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "smaller-helping",
      "metadata": {
        "id": "smaller-helping"
      },
      "source": [
        "## Importing the dataset of labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm7fbhseKE_2",
        "outputId": "c5cb38a8-1d61-4059-987d-83d9cbbe36d2"
      },
      "id": "tm7fbhseKE_2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "homeless-magnet",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "homeless-magnet",
        "outputId": "7d6ff8b5-1c1b-4ce2-bce8-1606f8f39b86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID      NUMBER\n",
              "0      0  KLG1CA2555\n",
              "1      1     PGMN112\n",
              "2      2     PREANUP\n",
              "3      3     DZ17YXR\n",
              "4      4     PUI8BES\n",
              "..   ...         ...\n",
              "428  428      DZ1YXR\n",
              "429  429      KA1SER\n",
              "430  430      BCG986\n",
              "431  431      KLBOSS\n",
              "432  432    DL49AK49\n",
              "\n",
              "[433 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0efa33a-597e-4084-aa3e-a0599f066503\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>NUMBER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>KLG1CA2555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>PGMN112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PREANUP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>DZ17YXR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>PUI8BES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>428</td>\n",
              "      <td>DZ1YXR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>429</td>\n",
              "      <td>KA1SER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>430</td>\n",
              "      <td>BCG986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>431</td>\n",
              "      <td>KLBOSS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>432</td>\n",
              "      <td>DL49AK49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>433 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0efa33a-597e-4084-aa3e-a0599f066503')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0efa33a-597e-4084-aa3e-a0599f066503 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0efa33a-597e-4084-aa3e-a0599f066503');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa57653f-7a9c-4730-999c-39393c424062\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa57653f-7a9c-4730-999c-39393c424062')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa57653f-7a9c-4730-999c-39393c424062 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "labels",
              "summary": "{\n  \"name\": \"labels\",\n  \"rows\": 433,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 433,\n        \"samples\": [\n          \"425\",\n          \"75\",\n          \"181\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NUMBER\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 274,\n        \"samples\": [\n          \"AK0188\",\n          1245,\n          \"P018299\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No charts were generated by quickchart\n"
          ]
        }
      ],
      "source": [
        "labels=pd.read_excel('/content/drive/MyDrive/Copy of Kaggle_labels.xlsx')\n",
        "labels['ID']=labels['ID'].map(str)\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "physical-customs",
      "metadata": {
        "id": "physical-customs"
      },
      "source": [
        "## Functions used in the Contour Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "greater-lawrence",
      "metadata": {
        "id": "greater-lawrence"
      },
      "outputs": [],
      "source": [
        "def dist(x1, x2, y1, y2):\n",
        "    return ((x1-x2)**2+(y1-y2)**2)**0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duplicate-investigation",
      "metadata": {
        "id": "duplicate-investigation"
      },
      "source": [
        "## Functions used by YOLOv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "noble-handy",
      "metadata": {
        "id": "noble-handy"
      },
      "outputs": [],
      "source": [
        "# Load names of classes\n",
        "classesFile = \"/content/drive/MyDrive/classes.names\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "proper-tooth",
      "metadata": {
        "id": "proper-tooth"
      },
      "outputs": [],
      "source": [
        "# Give the configuration and weight files for the model and load the network using them.\n",
        "modelConfiguration = \"/content/drive/MyDrive/darknet-yolov3.cfg\";\n",
        "modelWeights = \"/content/drive/MyDrive/lapi.weights\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fleet-occurrence",
      "metadata": {
        "id": "fleet-occurrence"
      },
      "outputs": [],
      "source": [
        "confThreshold = 0.5  #Confidence threshold\n",
        "nmsThreshold = 0.4  #Non-maximum suppression threshold\n",
        "\n",
        "inpWidth = 416     #Width of network's input image\n",
        "inpHeight = 416     #Height of network's input image\n",
        "\n",
        "classes = None\n",
        "with open(classesFile, 'rt') as f:\n",
        "    classes = f.read().rstrip('\\n').split('\\n')\n",
        "\n",
        "net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "sophisticated-aircraft",
      "metadata": {
        "id": "sophisticated-aircraft"
      },
      "outputs": [],
      "source": [
        "# Get the names of the output layers\n",
        "def getOutputsNames(net):\n",
        "    # Get the names of all the layers in the network\n",
        "    layersNames = net.getLayerNames()\n",
        "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
        "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "sharp-biodiversity",
      "metadata": {
        "id": "sharp-biodiversity"
      },
      "outputs": [],
      "source": [
        "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
        "def postprocess(frame, outs):\n",
        "    frameHeight = frame.shape[0]\n",
        "    frameWidth = frame.shape[1]\n",
        "\n",
        "    # Scan through all the bounding boxes output from the network and keep only the\n",
        "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
        "    classIds = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            #if detection[4]>0.001:\n",
        "            scores = detection[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            #if scores[classId]>confThreshold:\n",
        "            confidence = scores[classId]\n",
        "            if confidence > confThreshold:\n",
        "                center_x = int(detection[0] * frameWidth)\n",
        "                center_y = int(detection[1] * frameHeight)\n",
        "                width = int(detection[2] * frameWidth)\n",
        "                height = int(detection[3] * frameHeight)\n",
        "                left = int(center_x - width / 2)\n",
        "                top = int(center_y - height / 2)\n",
        "                classIds.append(classId)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([left, top, width, height])\n",
        "\n",
        "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
        "    # lower confidences.\n",
        "    cropped=None\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
        "    for i in indices:\n",
        "        i = i[0]\n",
        "        box = boxes[i]\n",
        "        left = box[0]\n",
        "        top = box[1]\n",
        "        width = box[2]\n",
        "        height = box[3]\n",
        "\n",
        "        # calculate bottom and right\n",
        "        bottom = top + height\n",
        "        right = left + width\n",
        "\n",
        "        #crop the plate out\n",
        "        cropped = frame[top:bottom, left:right].copy()\n",
        "    if cropped is not None:\n",
        "        return cropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "classical-astronomy",
      "metadata": {
        "id": "classical-astronomy"
      },
      "outputs": [],
      "source": [
        "# Draw the predicted bounding box\n",
        "def drawPred(classId, conf, left, top, right, bottom, frame):\n",
        "    # Draw a bounding box.\n",
        "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
        "\n",
        "    label = '%.2f' % conf\n",
        "\n",
        "    # Get the label for the class name and its confidence\n",
        "    if classes:\n",
        "        assert(classId < len(classes))\n",
        "        label = '%s:%s' % (classes[classId], label)\n",
        "\n",
        "    #Display the label at the top of the bounding box\n",
        "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "    top = max(top, labelSize[1])\n",
        "    cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (0, 0, 255), cv2.FILLED)\n",
        "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "covered-laundry",
      "metadata": {
        "id": "covered-laundry"
      },
      "source": [
        "## Functions used in Character Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "champion-start",
      "metadata": {
        "id": "champion-start"
      },
      "outputs": [],
      "source": [
        "# Match contours to license plate or character template\n",
        "def find_contours(dimensions, img) :\n",
        "\n",
        "    # Find all contours in the image\n",
        "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Retrieve potential dimensions\n",
        "    lower_width = dimensions[0]\n",
        "    upper_width = dimensions[1]\n",
        "    lower_height = dimensions[2]\n",
        "    upper_height = dimensions[3]\n",
        "\n",
        "    # Check largest 5 or  15 contours for license plate or character respectively\n",
        "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
        "\n",
        "    ii = cv2.imread('contour.jpg')\n",
        "\n",
        "    x_cntr_list = []\n",
        "    target_contours = []\n",
        "    img_res = []\n",
        "    for cntr in cntrs :\n",
        "        # detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
        "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
        "\n",
        "        # checking the dimensions of the contour to filter out the characters by contour's size\n",
        "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
        "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
        "\n",
        "            char_copy = np.zeros((44,24))\n",
        "            # extracting each character using the enclosing rectangle's coordinates.\n",
        "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
        "            char = cv2.resize(char, (20, 40))\n",
        "\n",
        "            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
        "\n",
        "            # Make result formatted for classification: invert colors\n",
        "            char = cv2.subtract(255, char)\n",
        "\n",
        "            # Resize the image to 24x44 with black border\n",
        "            char_copy[2:42, 2:22] = char\n",
        "            char_copy[0:2, :] = 0\n",
        "            char_copy[:, 0:2] = 0\n",
        "            char_copy[42:44, :] = 0\n",
        "            char_copy[:, 22:24] = 0\n",
        "\n",
        "            img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n",
        "\n",
        "    # arbitrary function that stores sorted list of character indeces\n",
        "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
        "    img_res_copy = []\n",
        "    for idx in indices:\n",
        "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
        "    img_res = np.array(img_res_copy)\n",
        "\n",
        "    return img_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "western-refrigerator",
      "metadata": {
        "id": "western-refrigerator"
      },
      "outputs": [],
      "source": [
        "# Find characters in the resulting images\n",
        "def segment_characters(image) :\n",
        "\n",
        "    # Preprocess cropped license plate image\n",
        "    img_lp = cv2.resize(image, (333, 75))\n",
        "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
        "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
        "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
        "\n",
        "    LP_WIDTH = img_binary_lp.shape[0]\n",
        "    LP_HEIGHT = img_binary_lp.shape[1]\n",
        "\n",
        "    # Make borders white\n",
        "    img_binary_lp[0:3,:] = 255\n",
        "    img_binary_lp[:,0:3] = 255\n",
        "    img_binary_lp[72:75,:] = 255\n",
        "    img_binary_lp[:,330:333] = 255\n",
        "\n",
        "    # Estimations of character contours sizes of cropped license plates\n",
        "    dimensions = [LP_WIDTH/6,\n",
        "                       LP_WIDTH/2,\n",
        "                       LP_HEIGHT/10,\n",
        "                       2*LP_HEIGHT/3]\n",
        "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
        "\n",
        "    # Get contours within cropped license plate\n",
        "    char_list = find_contours(dimensions, img_binary_lp)\n",
        "\n",
        "    return char_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "usual-formation",
      "metadata": {
        "id": "usual-formation"
      },
      "source": [
        "## Loading the weights of CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "manufactured-montgomery",
      "metadata": {
        "id": "manufactured-montgomery"
      },
      "outputs": [],
      "source": [
        "# Create a new model instance\n",
        "loaded_model = Sequential()\n",
        "loaded_model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
        "loaded_model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "loaded_model.add(Dropout(0.4))\n",
        "loaded_model.add(Flatten())\n",
        "loaded_model.add(Dense(128, activation='relu'))\n",
        "loaded_model.add(Dense(36, activation='softmax'))\n",
        "\n",
        "# Restore the weights\n",
        "loaded_model.load_weights('/content/drive/MyDrive/my_checkpoint.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "precise-consensus",
      "metadata": {
        "id": "precise-consensus"
      },
      "outputs": [],
      "source": [
        "# Predicting the output\n",
        "def fix_dimension(img):\n",
        "  new_img = np.zeros((28,28,3))\n",
        "  for i in range(3):\n",
        "    new_img[:,:,i] = img\n",
        "  return new_img\n",
        "\n",
        "def show_results(count):\n",
        "    dic = {}\n",
        "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "    for i,c in enumerate(characters):\n",
        "        dic[i] = c\n",
        "\n",
        "    output = []\n",
        "    for i,ch in enumerate(char): #iterating over the characters\n",
        "        img_ = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
        "        img = fix_dimension(img_)\n",
        "        img = img.reshape(1,28,28,3) #preparing image for the model\n",
        "        y_ = loaded_model.predict_classes(img)[0] #predicting the class\n",
        "        character = dic[y_] #\n",
        "        output.append(character) #storing the result in a list\n",
        "\n",
        "    plate_number = ''.join(output)\n",
        "    if plate_number==row:\n",
        "        count+=1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "built-flexibility",
      "metadata": {
        "id": "built-flexibility"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "overall-divorce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "overall-divorce",
        "outputId": "8f497857-9fbf-4a9a-bbc3-1aa30bf30324"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c7857ce09a52>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mis_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NUMBER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "file_list=os.listdir(r\"/content/drive/MyDrive/Kaggle_dataset/images\")\n",
        "count=0\n",
        "for path in file_list:\n",
        "#for entry in labels['ID']:\n",
        "    input_path = '/content/drive/MyDrive/Kaggle_dataset/images'+path\n",
        "    is_video = False\n",
        "    no=path[:-4]\n",
        "\n",
        "    row=labels['NUMBER'].where(labels['ID'] == no).dropna().values[0]\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    outputFile = input_path + '_yolo_out_py.jpg'\n",
        "\n",
        "    while cv2.waitKey(1) < 0:\n",
        "\n",
        "        # get frame from the video\n",
        "        hasFrame, frame = cap.read() #frame: an image object from cv2\n",
        "\n",
        "        # Stop the program if reached end of video\n",
        "        if not hasFrame:\n",
        "            break\n",
        "\n",
        "        # Create a 4D blob from a frame.\n",
        "        try:\n",
        "            blob = cv2.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
        "        except:\n",
        "            break\n",
        "\n",
        "        # Sets the input to the network\n",
        "        net.setInput(blob)\n",
        "\n",
        "        # Runs the forward pass to get output of the output layers\n",
        "        outs = net.forward(getOutputsNames(net))\n",
        "\n",
        "        # Remove the bounding boxes with low confidence\n",
        "        cropped = postprocess(frame, outs)\n",
        "        if cropped is not None:\n",
        "            # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)\n",
        "            t, _ = net.getPerfProfile()\n",
        "            label = 'Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency())\n",
        "            #cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
        "\n",
        "            # Write the frame with the detection boxes\n",
        "            if is_video:\n",
        "                vid_writer.write(frame.astype(np.uint8))\n",
        "            else:\n",
        "                #plt.imshow(cropped)\n",
        "                #plt.show()\n",
        "                char=segment_characters(cropped)\n",
        "                count=show_results(count)\n",
        "        else:\n",
        "            ####\n",
        "            image = cv2.imread('test_dataset/images/'+path)\n",
        "            # Resize the image - change width to 500\n",
        "            image = imutils.resize(image, width=500)\n",
        "            img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # RGB to Gray scale conversion\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Noise removal with iterative bilateral filter(removes noise while preserving edges)\n",
        "            gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
        "\n",
        "            # Find Edges of the grayscale image\n",
        "            edged = cv2.Canny(gray, 170, 200)\n",
        "\n",
        "            # Find contours based on Edges\n",
        "            cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "            cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] #sort contours based on their area keeping minimum required area as '30' (anything smaller than this will not be considered)\n",
        "            NumberPlateCnt = None #we currently have no Number plate contour\n",
        "\n",
        "            # loop over our contours to find the best possible approximate contour of number plate\n",
        "            for c in cnts:\n",
        "                    peri = cv2.arcLength(c, True)\n",
        "                    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
        "                    if len(approx) == 4:  # Select the contour with 4 corners\n",
        "                        NumberPlateCnt = approx #This is our approx Number Plate Contour\n",
        "                        x,y,w,h = cv2.boundingRect(c)\n",
        "                        ROI = img[y:y+h, x:x+w]\n",
        "                        break\n",
        "\n",
        "            idx=0\n",
        "            m=0\n",
        "            if NumberPlateCnt is None:\n",
        "                continue\n",
        "            for i in range(4):\n",
        "                if NumberPlateCnt[i][0][1]>m:\n",
        "                    idx=i\n",
        "                    m=NumberPlateCnt[i][0][1]\n",
        "            if idx==0:\n",
        "                pin=3\n",
        "            else:\n",
        "                pin=idx-1\n",
        "            if idx==3:\n",
        "                nin=0\n",
        "            else:\n",
        "                nin=idx+1\n",
        "\n",
        "            p=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[pin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[pin][0][1])\n",
        "            n=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[nin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[nin][0][1])\n",
        "\n",
        "            if p>n:\n",
        "                if NumberPlateCnt[pin][0][0]<NumberPlateCnt[idx][0][0]:\n",
        "                    left=pin\n",
        "                    right=idx\n",
        "                else:\n",
        "                    left=idx\n",
        "                    right=pin\n",
        "                d=p\n",
        "            else:\n",
        "                if NumberPlateCnt[nin][0][0]<NumberPlateCnt[idx][0][0]:\n",
        "                    left=nin\n",
        "                    right=idx\n",
        "                else:\n",
        "                    left=idx\n",
        "                    right=nin\n",
        "                d=n\n",
        "            left_x=NumberPlateCnt[left][0][0]\n",
        "            left_y=NumberPlateCnt[left][0][1]\n",
        "            right_x=NumberPlateCnt[right][0][0]\n",
        "            right_y=NumberPlateCnt[right][0][1]\n",
        "\n",
        "            opp=right_y-left_y\n",
        "            hyp=((left_x-right_x)**2+(left_y-right_y)**2)**0.5\n",
        "            sin=opp/hyp\n",
        "            theta=math.asin(sin)*57.2958\n",
        "\n",
        "            image_center = tuple(np.array(ROI.shape[1::-1]) / 2)\n",
        "            rot_mat = cv2.getRotationMatrix2D(image_center, theta, 1.0)\n",
        "            result = cv2.warpAffine(ROI, rot_mat, ROI.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "\n",
        "            if opp>0:\n",
        "                h=result.shape[0]-opp//2\n",
        "            else:\n",
        "                h=result.shape[0]+opp//2\n",
        "\n",
        "            result=result[0:h, :]\n",
        "            char=segment_characters(result)\n",
        "            count=show_results(count)\n",
        "\n",
        "print(\"Accuracy: \"+str((count/166)*100)+\"%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}